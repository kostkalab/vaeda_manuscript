{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84699407-cd7f-41c5-8bd7-d725bdcfdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, average_precision_score\n",
    "\n",
    "\n",
    "from plot_results import get_dbl_metrics\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + np.exp(-(12*x)+6))\n",
    "    return sig\n",
    "\n",
    "def get_all_dbl_metrics(test, scores, labels, colors):\n",
    "    fig = plt.figure(figsize=(7,3),dpi=100)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    #ROC \n",
    "    for i, score in enumerate(scores):\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test, score, pos_label=1)\n",
    "        rauc = metrics.auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr,lw=2, label = labels[i], c = colors[i])\n",
    "    plt.plot([0,1],[0,1],'--',color ='black', lw=1)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    # precision recall curve\n",
    "    for i, score in enumerate(scores):\n",
    "        \n",
    "        precision, recall, thresholds = precision_recall_curve(test, score, pos_label=1)\n",
    "        prauc = metrics.auc(recall, precision)\n",
    "        \n",
    "        \n",
    "        plt.plot(recall, precision, lw=2, label = labels[i], c = colors[i])\n",
    "    random=len(test[test==1]) / len(test)\n",
    "    plt.plot([0, 1], [random, random], linestyle='--', c='black', lw=1)\n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.title(\"PR curve\")\n",
    "    plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ap = average_precision_score(test, score)\n",
    "    \n",
    "    return rauc, prauc, ap\n",
    "\n",
    "def plot_ROC(cols=7):\n",
    "    cmap='Paired'\n",
    "    num_data = scores.shape[2]\n",
    "    rows = np.ceiling(num_data/cols)\n",
    "    \n",
    "    fig,ax = plt.figure(rows, cols, figsize=(8.267717,10.8622), dpi=300)\n",
    "\n",
    "    for d in scores.shape[2]:\n",
    "        \n",
    "        scores_d = scores[:,:,d]\n",
    "        true_d   = true[:,:,d]\n",
    "        \n",
    "        for i, score in enumerate(scores_d):\n",
    "            #calculate ROC\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(true_d, score, pos_label=1)\n",
    "            rauc = metrics.auc(fpr, tpr)\n",
    "            #plot it\n",
    "            ax[d].plot(fpr, tpr,lw=2, label = labels[i])\n",
    "        ax[d].plot([0,1],[0,1],'--',color ='black', lw=1)\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.title('ROC curve')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return rauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f65bfb-52b2-4847-acdf-bc5512ce1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbl_metrics(test, score):\n",
    "    fig = plt.figure(figsize=(6,3),dpi=100)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    #ROC \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, score, pos_label=1)\n",
    "    rauc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr,lw=2, label='ROC curve (area = %0.2f)' % rauc)\n",
    "    plt.plot([0,1],[0,1],'--',color ='black', lw=1)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC (area = %0.2f)' % rauc)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    # precision recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(test, score, pos_label=1)\n",
    "    prauc = metrics.auc(recall, precision)\n",
    "    plt.plot(recall, precision, lw=2)\n",
    "    random=len(test[test==1]) / len(test)\n",
    "    plt.plot([0, 1], [random, random], linestyle='--', label='random', c='black', lw=1)\n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.title(\"PR curve (area = %0.2f)\" % prauc)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ap = average_precision_score(test, score)\n",
    "    \n",
    "    return rauc, prauc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa8913-0587-4221-9bd4-bc6e099d1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../results_manuscript/ROC_PR_Curves/'\n",
    "\n",
    "path = '../results_benchmark/'\n",
    "files = [f.split('_') for f in listdir(path) if (isfile(join(path, f)) and (f[-3:]=='csv'))]\n",
    "#files = np.sort(files)\n",
    "files = np.array(files)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438829d-4700-4535-8039-d6b8a405feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adecf5-d0cd-454e-94ac-d3f5cd2c59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Scrublet', 'bcds', 'cxds', 'hybrid', 'solo', 'DoubletFinder', 'scDblFinder', 'vaeda']\n",
    "data_names = np.sort(np.unique(files[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a094184-59cf-412f-b448-3b9dd2b36597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b683acc-726f-4822-a4d5-a7af23fd8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca9ac8-82a0-4f62-a50c-cd9e087e211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path + '_'.join(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f151d-e0ca-43c7-824d-0f481ac10825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data_name in data_names:\n",
    "    fs = files[files[:,0]==data_name]\n",
    "    \n",
    "    ano_path  = '../data/mtx_files/' + data_name + '_anno.csv'\n",
    "\n",
    "    #- READ IN BARCODE ANNOTATIONS\n",
    "    ano = pd.read_csv(ano_path)\n",
    "    true = pd.factorize(ano.x)[0]\n",
    "    labels = ano.x\n",
    "    if (labels[0]=='doublet'):\n",
    "        tmp = true + 3\n",
    "        tmp[tmp==3] = 1\n",
    "        tmp[tmp==4] = 0\n",
    "        true = tmp\n",
    "    \n",
    "    for method in methods:\n",
    "        f = fs[fs[:,1]==method]\n",
    "        \n",
    "        results = pd.read_csv(path + '_'.join(f[0]))\n",
    "        preds = results.doublet_scores  \n",
    "        \n",
    "        if (method == methods[0]):\n",
    "            all_preds = preds\n",
    "        else:\n",
    "            all_preds = np.vstack([all_preds, preds])\n",
    "    \n",
    "    colors = ['#6BBBDB', '#6BBBDB', '#8CCAE3', '#9CD2E7', '#8AD08D', '#A7DCA9', '#BEE5BF', '#d81e5b']\n",
    "    get_all_dbl_metrics(true, all_preds, methods, colors)\n",
    "    plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e7303-12f5-4319-bbc7-4f6817bed8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58e18b-8e31-4695-b30e-0905117912ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376cdad-b9b2-4d16-b509-2528c1f279e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, average_precision_score\n",
    "\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + np.exp(-(12*x)+6))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df2ffe-3c3e-41c7-8bcd-29c970f328b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../results_manuscript/ROC_PR_Curves/'\n",
    "\n",
    "path = '../results_benchmark/'\n",
    "files = [f.split('_') for f in listdir(path) if (isfile(join(path, f)) and (f[-3:]=='csv'))]\n",
    "#files = np.sort(files)\n",
    "files = np.array(files)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(scores, true, dataset_names, method_names, cols=8):\n",
    "    #width=210mm=8.267717in, height=275.9mm=10.8622in\n",
    "    cmap='Set3'\n",
    "    \n",
    "    num_data = len(scores)\n",
    "    rows = int(np.ceil(num_data/cols))\n",
    "    \n",
    "    width = 8.267717\n",
    "    width_p_plot = width / cols\n",
    "    height = rows*width_p_plot + rows*0.3\n",
    "        \n",
    "    #fig,ax = plt.subplots(rows, cols, figsize=(width,height), dpi=300)\n",
    "    fig,ax = plt.subplots(figsize=(width,height),sharex=True, sharey=True,dpi=300)\n",
    "    \n",
    "    for d in range(len(scores)):\n",
    "        \n",
    "        scores_d = scores[d]\n",
    "        true_d   = true[d]\n",
    "    \n",
    "        plt.subplot(rows,cols,d+1)\n",
    "        for i, score in enumerate(scores_d):\n",
    "            #calculate ROC\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(true_d, score, pos_label=1)\n",
    "            rauc = metrics.auc(fpr, tpr)\n",
    "            #plot it\n",
    "            plt.plot(fpr, tpr,lw=1, label = method_names[i])\n",
    "        plt.plot([0,1],[0,1],'--',color ='black', lw=0.5)\n",
    "        plt.title(dataset_names[d], fontsize=7)\n",
    "    \n",
    "    plt.suptitle('ROC curves')\n",
    "    fig.add_subplot(111, frameon=False)\n",
    "    plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return \n",
    "\n",
    "def plot_PRC(scores, true, dataset_names, method_names, cols=8):\n",
    "    #width=210mm=8.267717in, height=275.9mm=10.8622in\n",
    "    cmap='Set3'\n",
    "    \n",
    "    num_data = len(scores)\n",
    "    rows = int(np.ceil(num_data/cols))\n",
    "    \n",
    "    width = 8.267717\n",
    "    width_p_plot = width / cols\n",
    "    height = rows*width_p_plot + rows*0.3\n",
    "        \n",
    "    #fig,ax = plt.subplots(rows, cols, figsize=(width,height), dpi=300)\n",
    "    fig,ax = plt.subplots(figsize=(width,height),sharex=True, sharey=True,dpi=300)\n",
    "    \n",
    "    for d in range(len(scores)):\n",
    "        \n",
    "        scores_d = scores[d]\n",
    "        true_d   = true[d]\n",
    "    \n",
    "        plt.subplot(rows,cols,d+1)\n",
    "        for i, score in enumerate(scores_d):\n",
    "            precision, recall, thresholds = precision_recall_curve(true_d, score, pos_label=1)\n",
    "            prauc = metrics.auc(recall, precision)\n",
    "            plt.plot(recall, precision, lw=1, label = method_names[i])\n",
    "        random=len(true_d[true_d==1]) / len(true_d)\n",
    "        plt.plot([0, 1], [random, random], linestyle='--', c='black', lw=0.5)\n",
    "        plt.title(dataset_names[d], fontsize=7)\n",
    "    \n",
    "    plt.suptitle('PRC curves')\n",
    "    fig.add_subplot(111, frameon=False)\n",
    "    plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return \n",
    "\n",
    "def make_legend(method_names):\n",
    "    fig,ax = plt.subplots(figsize=(2,4), sharex=True, sharey=True,dpi=300)\n",
    "    \n",
    "    for method in method_names:\n",
    "        plt.plot([0,0,1],[0,1,1],label=method)\n",
    "        #plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "    plt.legend()\n",
    "    \n",
    "def make_legend_scatter(method_names):\n",
    "    fig,ax = plt.subplots(figsize=(2,4), sharex=True, sharey=True,dpi=300)\n",
    "    \n",
    "    for method in method_names:\n",
    "        plt.scatter([0,0,1],[0,1,1],label=method)\n",
    "        #plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a10c18-e7a1-4d2a-9fe0-2246b4de45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "true_list = []\n",
    "dataset_names=[]\n",
    "\n",
    "for data_name in data_names:\n",
    "    fs = files[files[:,0]==data_name]\n",
    "    \n",
    "    ano_path  = '../data/mtx_files/' + data_name + '_anno.csv'\n",
    "\n",
    "    #- READ IN BARCODE ANNOTATIONS\n",
    "    ano = pd.read_csv(ano_path)\n",
    "    true = pd.factorize(ano.x)[0]\n",
    "    labels = ano.x\n",
    "    if (labels[0]=='doublet'):\n",
    "        tmp = true + 3\n",
    "        tmp[tmp==3] = 1\n",
    "        tmp[tmp==4] = 0\n",
    "        true = tmp\n",
    "    \n",
    "    for method in methods:\n",
    "        f = fs[fs[:,1]==method]\n",
    "        \n",
    "        results = pd.read_csv(path + '_'.join(f[0]))\n",
    "        preds = results.doublet_scores  \n",
    "        \n",
    "        if (method == methods[0]):\n",
    "            all_preds = preds\n",
    "        else:\n",
    "            all_preds = np.vstack([all_preds, preds])\n",
    "    \n",
    "    scores.append(all_preds)\n",
    "    true_list.append(true)\n",
    "    dataset_names.append(data_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d984d-395b-4507-ba4b-4bcef8ad2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick', labelsize=5) \n",
    "plt.rc('ytick', labelsize=5) \n",
    "\n",
    "plot_ROC(scores, true_list, dataset_names, methods, cols=6)\n",
    "plt.savefig(save_path + 'ROC.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plot_PRC(scores, true_list, dataset_names, methods, cols=6)\n",
    "plt.savefig(save_path +'PRC.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "make_legend(methods)\n",
    "plt.savefig(save_path +'LEGEND.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d1fb4-6906-4103-b2c2-8c02f3537023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c22563-7cb0-4290-ae86-7f2d4f1398d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb02e2a-2da7-48b5-88c1-f6b13001a3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e344d6e-2f80-4a46-99c6-95046983c238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45a0c5-4b4f-455f-8571-e3b28758b5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_legend_scatter(methods)\n",
    "plt.savefig(save_path +'LEGEND_scatter.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411428d2-ff49-46a6-abd9-3cd18b77f5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbd993-7e56-4c85-8d5a-c8893efdb924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ac1e9-8475-4480-9d51-f612f774f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_name in data_names:\n",
    "    df = df_pr[df_pr.data_name == data_name]\n",
    "    \n",
    "    sns.set(rc={\"figure.figsize\":(16, 4)})\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    v = sns.violinplot(x='frac', y='score', data=df, inner='quartile', \n",
    "                   hue='method', palette=\"Set2\", linewidth=0, hue_order=methods)# ax2.set_aspect(\"equal\")\n",
    "    plt.setp(v.collections, alpha=.3)\n",
    "\n",
    "    sns.swarmplot(x='frac', y='score', data=df, hue='method', palette=\"Set2\", dodge=True, size=3,\n",
    "                          hue_order=methods)\n",
    "    df_means = df.groupby(['method','frac'])['score'].agg('mean').reset_index().sort_values(['frac'], ascending=False)\n",
    "    sns.swarmplot(x='frac', y='score', data=df_means, marker='o', hue='method', palette=\"Set2\", s=2, dodge=True,\n",
    "                          linewidth=1, edgecolor='black', hue_order=methods)\n",
    "\n",
    "    cell_num = np.unique(df['cell num'])\n",
    "    ax3 = ax1.twiny()\n",
    "    ax3.set_xlim([ax1.get_xlim()[0],ax1.get_xlim()[1]])\n",
    "    ax3.set_xticks(ax1.get_xticks())\n",
    "    ax3.set_xticklabels(cell_num)\n",
    "    ax3.tick_params(top=True)\n",
    "    ax3.set_xlabel('cell number')\n",
    "    ax3.spines['top'].set_visible(True)\n",
    "\n",
    "    ax1.set_ylabel('AUPRC')\n",
    "    plt.title(data_name, fontsize=15)\n",
    "    ax1.legend([],[], frameon=False)\n",
    "    \n",
    "    ax1.grid(axis='y')\n",
    "    #ax3.grid(axis='x')\n",
    "    \n",
    "    plt.savefig(save_path + data_name + '_PR_violin.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf5ab0-1f4a-4381-85f5-0713bac58239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29843143-17c9-4d27-8693-e88f6170480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = true_list\n",
    "\n",
    "plt.rc('xtick', labelsize=5) \n",
    "plt.rc('ytick', labelsize=5) \n",
    "#cols = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "#plt.rcParams['axes.prop_cycle'] = cycler('color', cols[:len(method_names)])\n",
    "\n",
    "dfs=[]\n",
    "\n",
    "for d in range(len(scores)):\n",
    "\n",
    "    scores_d = scores[d]\n",
    "    true_d   = true[d]\n",
    "    \n",
    "    for i, score in enumerate(scores_d):\n",
    "        \n",
    "        num = int(np.round(len(score) *0.05))\n",
    "        call = true_d[np.argsort(score)[-num:]]\n",
    "        \n",
    "        total = np.sum(true_d)\n",
    "        frac = np.sum(call) / total        \n",
    "        m = methods[i]\n",
    "        data = data_names[d]\n",
    "        \n",
    "        dfs.append(pd.DataFrame({'%captured':[frac], 'method':[m], 'data_name':[data]}))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43067a77-947e-4c60-9c53-9535926e75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752605c-6ed1-433f-a20f-2c20bfac7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0479caa-6f8e-49d3-9528-693e860b610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7b1ca-63da-42fd-a9aa-07ce7a71f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(16, 4)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.swarmplot(x='data_name', y='%captured', data=df, hue='method', palette=\"Set2\", dodge=True, size=5,\n",
    "              hue_order=methods)\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.tight_layout()      \n",
    "plt.savefig(save_path +'top_scores.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e1312-09d0-4e0c-8f27-882ace4f90cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe1cf0-94ec-4362-9b20-152b5c788c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0323c-f582-4210-884e-8841cceea0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826cd1d-baf3-45df-8a5d-b116ac2f2104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-majority",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
